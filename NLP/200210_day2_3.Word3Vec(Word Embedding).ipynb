{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T02:30:25.747986Z",
     "start_time": "2020-02-10T02:30:25.743978Z"
    }
   },
   "source": [
    "# word embedding\n",
    "#### 자연어를 처리할 때 count기반 문제\n",
    "- 차원이 너무 커지는 문제\n",
    "- 희소 차원임이 문제\n",
    "- 단어의 의미의 차이를 알 수 없음.\n",
    "- 거리를 계산할 수 있지만, (유사도를 비교할 순 있지만) 논리적인 의미를 알 수는 없음.\n",
    "\n",
    "\n",
    "#### word embedding\n",
    "- 단어간의 의미를 나타내고\n",
    "- dense한 형태로 나타내보자\n",
    "- 단어를 다차원 공간에 표현(의미를 갖는 벡터 공간에)\n",
    "\n",
    "> 단어의 의미 자체를 다차원 공간에서 벡터화 필요\n",
    "- 단어들 사이의 유사도 측정 가능\n",
    "- 단어들간의 평균, 및 연산을 통해 추론 가능\n",
    "- king - man = queen - woman => 단어간의 의미를 추론할 수 있음.!\n",
    "\n",
    "> 벡터 계산\n",
    "- va + vb = vc\n",
    "- va - vb=>b에서 시작해서 a로 가는 벡터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T02:30:25.747986Z",
     "start_time": "2020-02-10T02:30:25.743978Z"
    }
   },
   "source": [
    "# 방법\n",
    "## 1.  Continous Bag of Words\n",
    "- 주변 단어(문맥, context)들을 가지고 중간에 있는 단어(center word)들을 예측하는 방법\n",
    "- The fat cat sat on the mat -> 중심단어: sat\n",
    "- 중심 단어는 주변 단어들과 관련이 있기 때문에 \n",
    "- 주변 단어: train data, 중심단어: y data 개념\n",
    "\n",
    " ### 1.1. 과정\n",
    " > 윈도우 슬라이딩을 통해 데이터셋 생성\n",
    " - 첫단어부터 중심단어로 설정해서, 주변 단어를 몇 개를 볼지 설정한 후, 주변 단어를 1로 놓고, 나머지는 0으로 설정\n",
    " - 단어를 옆으로 가면서, 주변단어들을 1로 설정하기\n",
    " - 한 문장내에서 윈도구 크기만큼 스캐닝을 하면서 training data 만들기\n",
    " - 중심단어: y , 주변단어: x data\n",
    " \n",
    " ### 1.2 네트워크 구성\n",
    " #### input -> projection layer -> pred(softmax) -> y라벨\n",
    " > input: 주변단어들(one hot) -> demension이 큼.\n",
    " - input shape(데이터를 column vector로 파악): \n",
    " - 행-V(단어수), 열 - 주변단어를 onehot 인코딩한 결과\n",
    " \n",
    " > outout: 중심단어들(one hot)\n",
    "  - y 라벨이 one hot이기 때문에 class의 개수가 매우 큼\n",
    " - V: 단어수\n",
    " \n",
    " > projection layer거치기(= 정사영)\n",
    " >> W: ( V 차원 -> M 차원으로 줄이기)\n",
    " - 실제로 신경망 알고리즘을 사용하지는 않음.\n",
    " - y= Wx 개념(b, 활성화 함수 개념 없음)\n",
    " - projectin의 개념:축 * 단위 벡터\n",
    " - 축: 단위벡터 * 벡터 = 벡터\n",
    " - 축: 단위벡터를 특정 방향으로 회전, 변환한 뒤 * 벡터\n",
    " - 특정 방향으로 단위 벡터를 곱하는 것: 프로젝션\n",
    " - x: 주변 단어\n",
    " - W: weight 매트릭스: (M, V)차원\n",
    " - M: 처음에 V였던 큰 디멘젼을 M 차원으로 바꾸고 싶을 때\n",
    " - 모든 축을 사용하지 않고, v개 만큼의 축이 있을 때 M개 만큼의 축을 선택하는 개념.(의미 없는 축 줄이기)\n",
    " \n",
    " >> 2차원 데이터-> 1차원 데이터로 줄이기\n",
    " - 2차원을 아무렇게나 1차원으로 줄이면 오류가 생기므로\n",
    " - (8, 10) 중 값을 1개만 사용하면 8 or 10 이므로 정보가 많이 소실됨.\n",
    " - 만약 (10, 8)이라는 데이터가 있다면 원점을 \n",
    " - 원점 이동 + 회전 이동하고 variance가 적은 축을 버림  -> 2차원 데이터를 1차원으로 변환가능=> 프로젝션\n",
    " - 모든 축을 사용하지 않고, v개 만큼의 축이 있을 때 M개 만큼의 축을 선택하는 개념.(의미 없는 축 줄이기)\n",
    " \n",
    " >> W': M차원-> 다시 V차원으로 늘리기\n",
    " - W'을 구하기\n",
    " - W' = V* M차원 -> err값을 계산하기 위해서만 사용하는 값. 실제로는 W만 사용\n",
    " - yhat = softmax(Z)\n",
    " - v차원으로 늘리는 이유: y라벨의 차원이 v이기 때문에\n",
    " - Z = \n",
    " \n",
    " >> cross entropy\n",
    " - yhat과 y를 비교해서 loss를 최소화하면 W, W'를 학습시킴.\n",
    " - 실제로는 W만 사용하고, W'은 학습용도로만 사용\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:17:04.228327Z",
     "start_time": "2020-02-10T05:17:00.160938Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import matplotlib.pyplot as plt\n",
    "import codecs\n",
    "from konlpy.tag import Twitter\n",
    "from gensim.models import word2vec\n",
    "from konlpy.utils import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from konlpy.tag import Twitter\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma \n",
    "from konlpy.tag import Twitter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from gensim import corpora, models\n",
    "import numpy  as np\n",
    "from PIL import Image\n",
    "from wordcloud import ImageColorGenerator\n",
    "import glob\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:31:04.243072Z",
     "start_time": "2020-02-10T04:31:04.238919Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "                ['this', 'is', 'a',   'good',      'product'],\n",
    "                ['it',   'is', 'a',   'excellent', 'product'],\n",
    "                ['it',   'is', 'a',   'bad',       'product'],\n",
    "                ['that', 'is', 'the', 'worst',     'product']\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:33:18.797923Z",
     "start_time": "2020-02-10T04:33:18.781966Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문장을 이용하여 단어와 벡터를 생성한다.-> W를 구함.\n",
    "# 모델 만들기\n",
    "model = Word2Vec(sentences,\n",
    "                size = 20,  # vector의 차원\n",
    "                window = 3, # 주변 단어를 몇개 볼것인가\n",
    "                min_count = 1 # 최소 단어가 1번 나오는 것을 고려할 것이다\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:37:08.481001Z",
     "start_time": "2020-02-10T04:37:08.477656Z"
    }
   },
   "source": [
    "#### 생성된 vector확인\n",
    "\n",
    "- 단어별로 고정된 차원(feature가 생성)이 만들어졋으므로 \n",
    "- 뒤에 이어서 모델을 만들 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:37:48.729035Z",
     "start_time": "2020-02-10T04:37:48.725901Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단어벡터를 구한다.\n",
    "word_vectors = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:37:49.194738Z",
     "start_time": "2020-02-10T04:37:49.190695Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02282666,  0.01874459,  0.0102811 ,  0.01935314,  0.00382596,\n",
       "        0.01362558, -0.01492825, -0.01112475, -0.02164873, -0.00368071,\n",
       "       -0.01426504, -0.00270334,  0.01467235,  0.0106786 ,  0.00282609,\n",
       "       -0.02085758,  0.0165635 , -0.00653741,  0.02071085,  0.00148028],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'this'라는 단어의 벡터. \n",
    "# 원래 희소 행렬인데, size = 20차원으로 정했으므로, 20차원의 벡터로 변환됨.\n",
    "word_vectors['this']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떤 단어들이 있는지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:42:06.403804Z",
     "start_time": "2020-02-10T04:42:06.398817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['this', 'is', 'a', 'good', 'product', 'it', 'excellent', 'bad', 'that', 'the', 'worst'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = word_vectors.vocab.keys()\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:41:56.395470Z",
     "start_time": "2020-02-10T04:41:56.390549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('this', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E02C8>), ('is', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0388>), ('a', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0408>), ('good', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0448>), ('product', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E04C8>), ('it', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0708>), ('excellent', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0748>), ('bad', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E07C8>), ('that', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0488>), ('the', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0608>), ('worst', <gensim.models.keyedvectors.Vocab object at 0x000001A56C0E0848>)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.vocab.items()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전체 단어 vector 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:17:12.414017Z",
     "start_time": "2020-02-10T05:17:12.406971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.02282666,  0.01874459,  0.0102811 ,  0.01935314,  0.00382596,\n",
      "        0.01362558, -0.01492825, -0.01112475, -0.02164873, -0.00368071,\n",
      "       -0.01426504, -0.00270334,  0.01467235,  0.0106786 ,  0.00282609,\n",
      "       -0.02085758,  0.0165635 , -0.00653741,  0.02071085,  0.00148028],\n",
      "      dtype=float32), array([ 0.00675884,  0.00153364, -0.00950851,  0.00809686, -0.00918463,\n",
      "        0.01064638, -0.02291108,  0.00371675,  0.00851044, -0.00029214,\n",
      "       -0.01142824, -0.0002227 , -0.0088951 , -0.00245749,  0.01111678,\n",
      "       -0.0107454 , -0.01137813, -0.00131338, -0.00561119,  0.01871312],\n",
      "      dtype=float32), array([-0.01787574,  0.0005055 ,  0.00707273,  0.00433004, -0.02444712,\n",
      "        0.01246034, -0.01020078, -0.01451306, -0.01381973,  0.00220769,\n",
      "       -0.01941462,  0.0105362 ,  0.00326828, -0.01761376,  0.01424268,\n",
      "       -0.01527467,  0.00582997, -0.01815473,  0.00557335,  0.01154158],\n",
      "      dtype=float32), array([ 0.01855993, -0.00199658,  0.0123276 , -0.02363487,  0.00027415,\n",
      "       -0.01671041, -0.02181324,  0.01037625,  0.00208679,  0.02151044,\n",
      "       -0.00081333,  0.00261688, -0.01271601, -0.01179285,  0.00733754,\n",
      "        0.00965039, -0.01579179, -0.00565714, -0.02243581, -0.01320035],\n",
      "      dtype=float32), array([ 0.020386  ,  0.00793678,  0.00499275,  0.01221475,  0.01786171,\n",
      "        0.02473198, -0.00209911,  0.0198792 ,  0.02410196,  0.00573446,\n",
      "        0.01852051, -0.00803154,  0.0141065 , -0.00402346, -0.00276056,\n",
      "        0.01569363,  0.00863302,  0.00474567, -0.0040749 ,  0.0125176 ],\n",
      "      dtype=float32), array([-0.01938205, -0.00525202,  0.00764947,  0.01755921, -0.01393794,\n",
      "        0.01443719,  0.017193  , -0.00819866,  0.02164726, -0.00309052,\n",
      "       -0.00991397,  0.0020565 , -0.00831548,  0.0007831 , -0.01865765,\n",
      "       -0.02086268, -0.00182314, -0.01223553, -0.01015162,  0.01236419],\n",
      "      dtype=float32), array([-0.01901641, -0.02075804, -0.00440359, -0.00523143,  0.00942118,\n",
      "       -0.01293601, -0.02150723,  0.00958412,  0.00406647,  0.01980827,\n",
      "       -0.0131879 , -0.00488824, -0.01372875,  0.02327634, -0.00348633,\n",
      "        0.01493798, -0.01889274,  0.01671538,  0.02116828, -0.01320067],\n",
      "      dtype=float32), array([-0.00601544, -0.02067999,  0.01629475,  0.0011608 , -0.01785601,\n",
      "        0.01414437, -0.01386248, -0.00654907,  0.00253389,  0.01688103,\n",
      "       -0.00768391, -0.00023674, -0.02070897, -0.00336881, -0.00369189,\n",
      "        0.01018642, -0.01129516,  0.01437068, -0.02195526,  0.00292374],\n",
      "      dtype=float32), array([ 0.00772705,  0.00178664,  0.00975861, -0.0209864 , -0.02467605,\n",
      "       -0.01323409, -0.00712661,  0.0043338 ,  0.00304945,  0.0007573 ,\n",
      "        0.00322374,  0.0178119 , -0.02095725,  0.01332988,  0.01669288,\n",
      "        0.00099164,  0.01727255,  0.00058218, -0.01900974,  0.01192635],\n",
      "      dtype=float32), array([-0.00569888, -0.00369   , -0.00223579, -0.01171787,  0.02494405,\n",
      "        0.01265352, -0.00137275, -0.00281759, -0.00252034, -0.00813951,\n",
      "       -0.01452192, -0.01757323, -0.01728393, -0.01811455,  0.00383014,\n",
      "        0.00147075,  0.01983519, -0.00847577,  0.00328409, -0.01946819],\n",
      "      dtype=float32), array([-0.02229915,  0.0185696 ,  0.0202511 , -0.02248923,  0.02245778,\n",
      "       -0.01965296,  0.01723466,  0.00827649,  0.00388762, -0.01436902,\n",
      "       -0.00807779,  0.00815833, -0.01538261,  0.01523471,  0.01557415,\n",
      "        0.00820868,  0.02376429, -0.01891982, -0.01413288,  0.02468227],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "word_vectors_list = [word_vectors[v] for v in vocabs]\n",
    "print(word_vectors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. 유사도 확인 : 코사인 distance로 확인\n",
    "\n",
    "####  cos유사도: 각도로 확인\n",
    "- 같으면 1 -> cos(0도 )= 1\n",
    "- 다르면 0 -> cos(90도) = 0\n",
    "- 결과 : -1 -> 반대 방향, cos(180) = -1\n",
    "\n",
    "\n",
    "####  유클리안 거리와의 차이점\n",
    "- 다른 두 벡터 안에 있는 두 점을 비교할 대(비례 관계의 삼각형)\n",
    "- 유클리디안 거리로는 거리가 다르지만\n",
    "- cos거리로는 같을 수 있음.->각도만 비교하기 때문\n",
    "\n",
    "> cos\n",
    "- 각도만 확인, 방향만 확인\n",
    "- 정확하게 거리까지는 계산하지 않음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:49:30.739474Z",
     "start_time": "2020-02-10T04:49:30.734488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14636609"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('it', 'this')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주어진 단어와 가장 유사한 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:49:19.490781Z",
     "start_time": "2020-02-10T04:49:19.485796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0.33982735872268677), ('bad', 0.25683528184890747)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('it', topn = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:49:24.827890Z",
     "start_time": "2020-02-10T04:49:24.821876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0.33982735872268677),\n",
       " ('bad', 0.25683528184890747),\n",
       " ('is', 0.1931551843881607),\n",
       " ('this', 0.14636608958244324),\n",
       " ('worst', 0.05984010919928551),\n",
       " ('that', -0.06858645379543304),\n",
       " ('product', -0.06895763427019119),\n",
       " ('the', -0.11150475591421127),\n",
       " ('excellent', -0.23884126543998718),\n",
       " ('good', -0.40791821479797363)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T04:50:55.090833Z",
     "start_time": "2020-02-10T04:50:55.086890Z"
    }
   },
   "source": [
    "## 1.4.  활용\n",
    "#### 지금까지는 단어를 기준으로 한것.\n",
    "#### 문장은 단어로 이루어져 있고, 우리는 문장에 관심이 있음\n",
    "- 단어별로 embedding 하면 테마별로 같은 주제의 단어들은 관련된 단어끼리 뭉쳐있을 것.\n",
    "- 임의의 문장이 주어졌을 때 평균을 구하면 어느 주제에 속했는지 알 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 네이버 리뷰 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. data\n",
    "- 데이터는 문장들의 집합으로 구성\n",
    "- 리스트 안에 리스트 형태로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:15:28.819385Z",
     "start_time": "2020-02-10T05:15:28.551016Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, encoding = 'utf-8', mode = 'r') as f:\n",
    "        data = [line.split('\\t') for line in f.read() .splitlines()]\n",
    "        data = data[1:] # header 제외\n",
    "    return data\n",
    "\n",
    "rating_train = read_data('ratings_train.txt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:15:39.162935Z",
     "start_time": "2020-02-10T05:15:39.157941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3819312', '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분석기로 단어 선별하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:17:16.554541Z",
     "start_time": "2020-02-10T05:17:16.207361Z"
    }
   },
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:03.978270Z",
     "start_time": "2020-02-10T05:21:03.974262Z"
    }
   },
   "outputs": [],
   "source": [
    "# 형태소 분석해서 '단어/형태소 ' 형태로 만들기\n",
    "def tokens(doc):\n",
    "    return ['/'.join(t) for t in okt.pos(doc, norm = True, stem = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:21:05.431656Z",
     "start_time": "2020-02-10T05:21:05.405603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['흠/Noun',\n",
       " '.../Punctuation',\n",
       " '포스터/Noun',\n",
       " '보고/Noun',\n",
       " '초딩/Noun',\n",
       " '영화/Noun',\n",
       " '줄/Noun',\n",
       " '..../Punctuation',\n",
       " '오버/Noun',\n",
       " '연기/Noun',\n",
       " '조차/Josa',\n",
       " '가볍다/Adjective',\n",
       " '않다/Verb']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens(rating_train[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:30:03.353932Z",
     "start_time": "2020-02-10T05:30:03.329980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아 더빙.. 진짜 짜증나네요 목소리',\n",
       " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       " '너무재밓었다그래서보는것을추천한다',\n",
       " '교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정',\n",
       " '사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다',\n",
       " '막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.',\n",
       " '원작의 긴장감을 제대로 살려내지못했다.',\n",
       " '별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네',\n",
       " '액션이 없는데도 재미 있는 몇안되는 영화',\n",
       " '왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = []\n",
    "for row in rating_train:\n",
    "    docs.append(row[1])\n",
    "docs[:10]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T06:05:56.790361Z",
     "start_time": "2020-02-10T06:05:56.785398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150000"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)  # 15000차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:28:14.518531Z",
     "start_time": "2020-02-10T05:23:09.981161Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [tokens(d) for d in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:30:08.282942Z",
     "start_time": "2020-02-10T05:30:08.267277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아/Exclamation',\n",
       " '더빙/Noun',\n",
       " '../Punctuation',\n",
       " '진짜/Noun',\n",
       " '짜증나다/Adjective',\n",
       " '목소리/Noun']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:51:43.527749Z",
     "start_time": "2020-02-10T05:51:35.902323Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(data,\n",
    "                    size = 100, # 100차원\n",
    "                    window = 3,\n",
    "                    min_count = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:32:38.920982Z",
     "start_time": "2020-02-10T05:32:38.774081Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v_model.save('namver.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T06:04:14.914547Z",
     "start_time": "2020-02-10T06:04:14.911557Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단어벡터를 구한다.\n",
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 총 단어 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T06:04:26.385929Z",
     "start_time": "2020-02-10T06:04:26.382937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21093"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_vectors.vocab.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:42:33.318744Z",
     "start_time": "2020-02-10T05:42:33.311809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('여자/Noun', 0.8384658098220825),\n",
       " ('할아버지/Noun', 0.7300465703010559),\n",
       " ('여자애/Noun', 0.7137463092803955),\n",
       " ('꼬마/Noun', 0.7094213962554932),\n",
       " ('아빠/Noun', 0.7092002630233765)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 남자 + 여배우 = 배우 = 여자\n",
    "# 남자 - 배우 = 여자 - 여배우\n",
    "# u' : 유니코드 인코딩 방식임.->안써도 됨..(editor가 unicode이므로 상관없음.)\n",
    "w2v_model.wv.most_similar(positive = tokens(u'남자 여배우'),\n",
    "                          negative = tokens(u'배우'),\n",
    "                          topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:42:19.629002Z",
     "start_time": "2020-02-10T05:42:19.623057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('엄태웅/Noun', 0.8701173067092896),\n",
       " ('김희선/Noun', 0.8696517944335938),\n",
       " ('강지환/Noun', 0.8648170232772827),\n",
       " ('김윤석/Noun', 0.8604189157485962),\n",
       " ('박예진/Noun', 0.8580924272537231),\n",
       " ('최민식/Noun', 0.8521853685379028),\n",
       " ('패닝/Noun', 0.8500890731811523),\n",
       " ('노튼/Noun', 0.850029468536377),\n",
       " ('홍경인/Noun', 0.8488479852676392),\n",
       " ('강동원/Noun', 0.8487983345985413)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(tokens('정우성'))\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-10T05:48:14.280302Z",
     "start_time": "2020-02-10T05:48:14.264627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('쇼타/Noun', 0.9126518964767456),\n",
       " ('야수/Noun', 0.9064512252807617),\n",
       " ('나토/Noun', 0.9046880006790161),\n",
       " ('화이트/Noun', 0.9034017324447632),\n",
       " ('칠이/Noun', 0.9013214111328125),\n",
       " ('썬더/Noun', 0.8994128704071045),\n",
       " ('해리/Noun', 0.8974124193191528),\n",
       " ('스타크/Noun', 0.8965331315994263),\n",
       " ('엠마/Noun', 0.8950753211975098),\n",
       " ('네스/Noun', 0.894395112991333)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(tokens('토르'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
