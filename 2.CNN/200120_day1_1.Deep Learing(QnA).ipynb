{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 질문\n",
    "1. 기계학습과 딥러닝의 차이점은?\n",
    "2. 경사하강법 그림으로 표현하면?\n",
    "3. 가중치는 신경망의 어디에 해당하는가?\n",
    "4. 어떻게 다층으로 복잡한 문제를 풀 수 있는가?\n",
    "5. 다층학습이 어려운가?\n",
    "6. 활성화는 비선형이어야하는가?\n",
    "7. 시그모이드 함수의 장점은?\n",
    "8. y= wx + b에서 b는 왜 필요한가?\n",
    "9. 딥러닝의 핵심 돌파구는?\n",
    "10. 왜 CNN을 특징 추출과 분류기 결합으로 보는가?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 기계학습과 딥러닝의 차이점은?\n",
    "- AI > Machin Learning > Deep Learning\n",
    "> 기계학습, 딥러닝\n",
    "- 주어진 데이터를 통해서 모델링을 통해 예측, 분류를 하는 것\n",
    "\n",
    "> 딥러닝\n",
    "- 신경망을 이용하여 반복적인 최적화 방법을 찾아서 찾는 것\n",
    "\n",
    "## 선형모양의 데이터들이 있을 때 푸는 방법\n",
    "> 1. 방정식 (전통적인 방법)\n",
    "- 두 점을 알고 있을 때 직선의 방정식 풀기\n",
    "- 가우시안 소거법\n",
    "- y1 = ax1 + b , y2 = ax2 + b......=> a, b를 도출\n",
    "- 기계학습은 수학 베이스로 방정식을 만들어서 풀기\n",
    "- 최소 자승법으로 풀기\n",
    "\n",
    "> 2. 머신러닝\n",
    "- SVM 등의 알고리즘 사용\n",
    "- closed function\n",
    "\n",
    "> 3. 딥러닝\n",
    "- 반복적인 최적화 방법(경사하강법)을 사용-> a, b를 찾기\n",
    "- 반복적인 알고리즘(신경망)\n",
    "- 신경망 = 경사하강법\n",
    "- 단점: 매우 느림\n",
    "- 장점: 다층(계층 구조)으로 네트워크 설계 가능-> 복잡한 문제를 풀 수 있음.\n",
    "- 딥러닝: 깊이가 깊은 네트워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 생물학적인 신경망에서 가중치는 어디에 해당하는가?\n",
    "\n",
    "> 딥러닝의 신경망(NN)\n",
    "- 생물학적인 신경망을 모델링한 것이므로\n",
    "\n",
    "> 가중치는\n",
    "- 신경과 신경이 붙어 있지 않음. \n",
    "- 시냅스: 축삭돌기와  수상돌기를 연결하는 부분\n",
    "- 시냅스를 통해서 전달되는 신경전달물질이 얼마나 분비되느냐에 따라 다음 뉴런으로 전달이 안됨.\n",
    "- 가중치 == 신경전달물질\n",
    "\n",
    "\n",
    "> y = wx에서\n",
    "- w의 크기에 따라 입력신호의 값을 조절할 수 있음.\n",
    "- x가 커도 w가 작으면 y값을 조절할 수 있음.\n",
    "\n",
    "### b의 역할: 역치(threshold)의 개념\n",
    "> b의 역할 : 역치의 개념!!!!!!!!!!\n",
    "- y = Σ Wx > b  => y = Σ wx- b >0\n",
    "- b보다 크면 활성화\n",
    "- b보다 작으면 비활성화\n",
    "- b: 가중치, 역치값(threshold), y절편, \n",
    "- 수학적으로 간단하게 모델링하기 위해  y = wx- b >0 으로 변경\n",
    "\n",
    "> y = 시그마wx- b >0\n",
    "- 신경망에서 bias라고 부름.\n",
    "- y절편, \n",
    "\n",
    "> 좀 더 단순하게 표현하면 y = Σ wx\n",
    "- 입력값의 차원을 1차원 늘려서\n",
    "- 원래 input = [x1, x2, x3]\n",
    "- 1차원 늘려서 input= [x1, x2, x3, 1]로 적용해서 b를 없애기\n",
    "\n",
    "# 8. y= wx + b에서 b는 왜 필요한가?\n",
    "- 수식에서 b가 있는 경우도 있고, 없는 경우도 있음.\n",
    "- b가 있느냐 없느냐에 따라 deeplearing 결과에 영향이 큼\n",
    "\n",
    "> b가 없으면\n",
    "- 원점을 지나는 방정식을 가지고 경사하강법으로 문제를 풀어야함-\n",
    "- 원점을 지난다는 제약조건이 굉장히 큼\n",
    "\n",
    "> b의 역할\n",
    "- y = Σ Wx + b\n",
    "- wx의 모든 합계에 b를 더한 값\n",
    "- b가 있으면 전체적으로 모든 데이터에 대해 이동시킬 수 있음.\n",
    "\n",
    "> b를 없앨수도 있음.\n",
    "- 원점을 옮긴다는 개념으로...데이터들을 scaling하면 되기는 함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
