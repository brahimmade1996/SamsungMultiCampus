{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation(dog_and_cat)\n",
    "- https://keraskorea.github.io/posts/2018-10-24-little_data_powerful_model/\n",
    "- https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "- 학습 데이터로 1,000장의 고양이 사진과 1,000장의 강아지 사진을 사용 (kaggle  25,000자)\n",
    "- 검증 데이터로는 각각 400장 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:17:51.556232Z",
     "start_time": "2020-01-23T00:17:43.848394Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy  import expand_dims\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "np.random.seed(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Augmentation 했을 때"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:20:10.094055Z",
     "start_time": "2020-01-23T00:20:09.744171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# 검증 및 테스트 이미지는 augmentation을 적용하지 않음(이미지 원본을 사용)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './smallcatdog/train', \n",
    "        target_size=(150, 150), \n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary') \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        './smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 2. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:20:49.682937Z",
     "start_time": "2020-01-23T00:20:49.551404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:22:45.571374Z",
     "start_time": "2020-01-23T00:21:07.039662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "125/125 [==============================] - 21s 170ms/step - loss: 0.7238 - accuracy: 0.5575 - val_loss: 0.6698 - val_accuracy: 0.5738\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 19s 148ms/step - loss: 0.6556 - accuracy: 0.6215 - val_loss: 0.5199 - val_accuracy: 0.6037\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 20s 158ms/step - loss: 0.6242 - accuracy: 0.6655 - val_loss: 0.5850 - val_accuracy: 0.6850\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 19s 153ms/step - loss: 0.5999 - accuracy: 0.6975 - val_loss: 0.4630 - val_accuracy: 0.7287\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 19s 155ms/step - loss: 0.5661 - accuracy: 0.7195 - val_loss: 0.9516 - val_accuracy: 0.5925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19294196dc8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# steps_per_epoch는 한 세대마다 몇 번 생성기로부터 데이터를 얻을지를 나타내는 값\n",
    "# 한 세대마다 사용되는 학습데이터의 수는 steps_per_epoch * batch_size\n",
    "        \n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,    # 2000/16     한번에 125개씩 생성\n",
    "        epochs=5,  #50\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)     # 800/16   한번에 50개씩 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 4. evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:26:28.182438Z",
     "start_time": "2020-01-23T00:26:27.951993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "0.574999988079071\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 5)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T00:27:39.697612Z",
     "start_time": "2020-01-23T00:27:39.694484Z"
    }
   },
   "source": [
    "# 2.augmentation 없이  학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:00:52.734361Z",
     "start_time": "2020-01-23T00:46:01.165551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Found 800 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.7339 - accuracy: 0.5150 - val_loss: 0.6982 - val_accuracy: 0.5412\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 17s 139ms/step - loss: 0.6759 - accuracy: 0.5995 - val_loss: 0.6277 - val_accuracy: 0.5800\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.6240 - accuracy: 0.6645 - val_loss: 0.6527 - val_accuracy: 0.6988\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.5729 - accuracy: 0.7165 - val_loss: 0.5978 - val_accuracy: 0.6950\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.5078 - accuracy: 0.7755 - val_loss: 0.6428 - val_accuracy: 0.6875\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.4626 - accuracy: 0.7825 - val_loss: 0.8733 - val_accuracy: 0.7200\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.3968 - accuracy: 0.8120 - val_loss: 0.4992 - val_accuracy: 0.7025\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.3670 - accuracy: 0.8345 - val_loss: 0.5419 - val_accuracy: 0.7350\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.3156 - accuracy: 0.8675 - val_loss: 1.0768 - val_accuracy: 0.6900\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.2706 - accuracy: 0.8920 - val_loss: 0.4484 - val_accuracy: 0.7188\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.2244 - accuracy: 0.9100 - val_loss: 1.1624 - val_accuracy: 0.6988\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.1906 - accuracy: 0.9290 - val_loss: 1.0765 - val_accuracy: 0.7212\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.1688 - accuracy: 0.9285 - val_loss: 1.4081 - val_accuracy: 0.7100\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1405 - accuracy: 0.9485 - val_loss: 1.5531 - val_accuracy: 0.7088\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.1195 - accuracy: 0.9515 - val_loss: 1.6609 - val_accuracy: 0.7125\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1096 - accuracy: 0.9630 - val_loss: 0.8927 - val_accuracy: 0.7113\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.0905 - accuracy: 0.9700 - val_loss: 2.3930 - val_accuracy: 0.7212\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 17s 140ms/step - loss: 0.0960 - accuracy: 0.9655 - val_loss: 1.9472 - val_accuracy: 0.7038\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.0910 - accuracy: 0.9700 - val_loss: 2.0548 - val_accuracy: 0.7200\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.0903 - accuracy: 0.9660 - val_loss: 0.5653 - val_accuracy: 0.6737\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0815 - accuracy: 0.9780 - val_loss: 1.4654 - val_accuracy: 0.7113\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0813 - accuracy: 0.9745 - val_loss: 3.4410 - val_accuracy: 0.6837\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.0809 - accuracy: 0.9765 - val_loss: 1.0216 - val_accuracy: 0.6862\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0690 - accuracy: 0.9780 - val_loss: 1.8468 - val_accuracy: 0.6963\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.0827 - accuracy: 0.9720 - val_loss: 2.8048 - val_accuracy: 0.6888\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 18s 147ms/step - loss: 0.0547 - accuracy: 0.9815 - val_loss: 1.6187 - val_accuracy: 0.7063\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0932 - accuracy: 0.9720 - val_loss: 3.2895 - val_accuracy: 0.6825\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0814 - accuracy: 0.9790 - val_loss: 1.5311 - val_accuracy: 0.6888\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0791 - accuracy: 0.9775 - val_loss: 6.2733 - val_accuracy: 0.6988\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0802 - accuracy: 0.9755 - val_loss: 1.3173 - val_accuracy: 0.6800\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.1019 - accuracy: 0.9710 - val_loss: 0.7543 - val_accuracy: 0.6637\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0799 - accuracy: 0.9740 - val_loss: 1.5706 - val_accuracy: 0.7075\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.0727 - accuracy: 0.9790 - val_loss: 4.8636 - val_accuracy: 0.7013\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1180 - accuracy: 0.9745 - val_loss: 1.2337 - val_accuracy: 0.7063\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 18s 146ms/step - loss: 0.0940 - accuracy: 0.9740 - val_loss: 0.2798 - val_accuracy: 0.7088\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.1206 - accuracy: 0.9635 - val_loss: 2.9666 - val_accuracy: 0.7125\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.1042 - accuracy: 0.9725 - val_loss: 1.1099 - val_accuracy: 0.7075\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.0892 - accuracy: 0.9745 - val_loss: 5.7187 - val_accuracy: 0.7100\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.0768 - accuracy: 0.9760 - val_loss: 0.7731 - val_accuracy: 0.7000\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 18s 144ms/step - loss: 0.1182 - accuracy: 0.9705 - val_loss: 1.5774 - val_accuracy: 0.6812\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.1367 - accuracy: 0.9650 - val_loss: 5.3640 - val_accuracy: 0.6837\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 18s 145ms/step - loss: 0.0981 - accuracy: 0.9745 - val_loss: 0.9125 - val_accuracy: 0.6925\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 18s 142ms/step - loss: 0.1260 - accuracy: 0.9605 - val_loss: 1.3151 - val_accuracy: 0.7038\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1107 - accuracy: 0.9725 - val_loss: 10.3215 - val_accuracy: 0.7100\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1053 - accuracy: 0.9735 - val_loss: 2.0461 - val_accuracy: 0.6950\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.1844 - accuracy: 0.9605 - val_loss: 0.8015 - val_accuracy: 0.6812\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1205 - accuracy: 0.9685 - val_loss: 2.6486 - val_accuracy: 0.7050\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 18s 140ms/step - loss: 0.1264 - accuracy: 0.9680 - val_loss: 0.6945 - val_accuracy: 0.7013\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 18s 143ms/step - loss: 0.1096 - accuracy: 0.9720 - val_loss: 2.6554 - val_accuracy: 0.6525\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.1544 - accuracy: 0.9565 - val_loss: 3.1196 - val_accuracy: 0.7000\n",
      "0.6000000238418579\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255 )\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 이미지를 배치 단위로 불러와 줄 generator입니다.\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'smallcatdog/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # 모든 이미지의 크기가 150x150로 조정됩니다.\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  # binary_crossentropy 손실 함수를 사용하므로 binary 형태로 라벨을 불러와야 합니다.\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=50, # 50\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size)\n",
    "\n",
    "# 구조, weight 모두 저장하기\n",
    "model.save(\"smallcatdog.h5\")\n",
    "scores = model.evaluate_generator( test_generator,       steps = 5)\n",
    "print(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:23:31.681017Z",
     "start_time": "2020-01-23T01:23:31.676030Z"
    }
   },
   "source": [
    "> 인공지능이 고 정밀도 실수 연산이 필요할까?\n",
    "- 비트 수(부동소스점) 연산에 이상이 있어도\n",
    "- 반복하다보니, 정밀도는 개선이 되고\n",
    "- 정밀도가 조금 떨어지더라도 고속 연산이 더 중요\n",
    "\n",
    "> GPU\n",
    "- 2000개 vs 1000 2개\n",
    "- 1000개짜기 가격이 더 싸고, 2개 사이에 연산이 이뤄지므로\n",
    "- 2000개는 빠르고, 그 안에서 모든 계산이 이뤄지기 때문에,\n",
    "- 여러개 gpu간의 병렬처리가 현실적"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. model save and load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. model architectrue, weight 모두 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('bicycleship.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:40:19.297895Z",
     "start_time": "2020-01-23T01:40:18.533811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 148, 148, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('smallcatdog.h5')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:40:53.363246Z",
     "start_time": "2020-01-23T01:40:51.134097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "0.2811466455459595\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'smallcatdog/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "scores = model2.evaluate_generator(test_generator, steps = 800//16)\n",
    "print(scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "(1, 32, 32, 3)\n",
      "[[1.0669018e-10 1.0000000e+00]]\n",
      "Probability that the image is a Bicycle: 1.0669018e-10\n",
      "Probability that the image is a Ship: 1.0\n"
     ]
    }
   ],
   "source": [
    "img_path = 'imagenet/ship.jpg'\n",
    "img = load_img(img_path, target_size=(32, 32))\n",
    "x = img_to_array(img)\n",
    "print(x.shape)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "print(x.shape)\n",
    "preds = model2.predict(x)\n",
    "\n",
    "print(preds)\n",
    "print('Probability that the image is a Bicycle:', preds[0,0])\n",
    "print('Probability that the image is a Ship:', preds[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
